---
title: CSAPP-虚拟内存
tags:
  - CSAPP
  - 读书笔记
  - 虚拟内存
---

一个系统的进程是与其他进程共享CPU和主存资源的。然而，共享主存会形成一些特殊的挑战。随着对CPU需求的增长，进程以某种合理的平滑方式慢下来。但是如果太多进程需要太多的内存，那么它们中的一些就根本无法运行。同时这种方式内存还十分容易被破坏。如果一个进程不小心写入另一个进程使用的内存，它可能以某种完全和程序逻辑无关的令人迷惑的方式失败。

<!--more-->

为了更加有效地管理内存并且减少出错，现代操作系统提供了一种对主存储器的抽象概念，叫做*虚拟内存（VM）*。虚拟内存为每一个进程提供了一个强大的一致的私有地址空间。通过一个清晰的机制，虚拟内存提供了三个重要的能力：

1. 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效的使用了主存。
2. 它为每个进程提供了一致的地址空间，从而简化了内存管理。
3. 它保护了每个进程的地址空间不被其他进程破环。

虚拟内存是计算机系统的一个重要的概念。它成功的一个主要原因是因为它可以沉默的自动的工作，不需要应用程序员的任何干涉。

这里将通过两个角度来看虚拟内存。本章的前一部分描述虚拟内存是如何工作的。后一部分将描述应用程序如何使用和管理虚拟内存。

### 1. 物理和虚拟寻址

计算机系统的主存被组织成为一个由M个连续的字节大小的单元组成的数组。每个字节都有一个唯一的*物理地址(Physical Address)*。这种结构中，CPU访问内存最自然的方式就是使用物理地址。我们把这种方式称为*物理寻址(physical addressing)*。

现代处理器使用一种称为是*虚拟寻址（virtual addressing）*，使用虚拟寻址，CPU通过生成一个虚拟地址(Virtual Address, VA)来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换成为物理地址的过程叫做*地址翻译(address translation)*。就像异常处理一样，地址翻译需要CPU硬件和操作系统之间的紧密合作。 CPU芯片上叫做*内存管理单元（Memory Management Unit，MMU）*的专用硬件，利用存放在主存中的查询来动态翻译虚拟地址，该表的内容由操作系统管理。

### 2. 地址空间

*地址空间(address space)*是一个非负整数地址的有序集合。如果地址空间中的整数是连续的，那我们就说它是一个*线性地址空间（linear address space）*。在一个带虚拟内存的系统中，CPU从一个有N=2^n个地址的地址空间中生成虚拟地址，这个地址空间称为*虚拟地址空间（virtual address space）*。

一个地址空间的大小是由表示的最大地址所需要的位数来描述的。例如，一个包含 N=2^n个地址的虚拟地址空间就叫做一个n位地址空间。现代系统通常支持32位或者64位虚拟地址空间。

一个系统还有一个*物理地址空间(physical address space)*， 对应于系统中物理内存的M个字节。

地址空间的概念十分重要，它清楚地区分了数据对象（字节）和它们的属性（地址）。一旦认识到这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间。这就是虚拟内存的基本思想。主存中的每个字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。

### 3. 虚拟内存作为缓存工具

概念上而言虚拟内存被组织成为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组。每一个字节都有一个唯一的虚拟地址，作为到数组的索引。磁盘中数组的内容被缓存到主存中。和存储器层次结构中的其他缓存一样，磁盘（较低层）上的数据被分隔成块，这些块作为磁盘和主存（较高层）之间的传输单元。VM系统通过将虚拟内存分割成为*虚拟页（Virtual Page， VP）*的大小固定块来处理这个问题。每个虚拟页的大小为P=2^p字节。类似地，物理内存被分割成为*物理页(Physical Page, PP)*，大小也为P字节（物理页中被称为 *（页帧（page frame）*）。

任何时刻，虚拟页面的集合都被分为三个不相交的子集：

* **未分配的 ：** VM系统还未被分配（或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何的磁盘空间。
* **缓存的 ：** 当前已缓存在物理内存中的已分配页
* **未缓存的 ：** 未缓存在物理内存中的已分配页

> 虚拟页（VP）存储在磁盘中，物理页（PP）缓存在DRAM中。

#### 3.1. DRAM缓存的组织结构

这里将使用*SRAM缓存*来表示位于CPU和主存之间的L1、L2和L3高速缓存，并且术语*DRAM缓存*来表示虚拟内存系统的缓存，它在主存缓存虚拟页中。

DRAM缓存大约比SRAM缓存慢了10倍，而磁盘要比DRAM慢了大约100000 多倍。因此，DRAM的缓存不命中比起SRAM的缓存不命中的代价要昂贵很多。而且，磁盘的随机读写要比连续读写要慢很多。所以，DRAM缓存的组织结构完全是由巨大的不命中开销驱动的。

这里因为巨大的不命中处罚，虚拟页往往很大，通常是4KB～2MB。由于不命中处罚，DRAM缓存是完全相联的，即任何虚拟页都可以放置在任何物理页中。不命中时的替换策略也很重要，因为替换错误的处罚非常之高。

#### 3.2. 页表

如同缓存一样，虚拟内存系统必须要某种方法判定一个虚拟内存页是否缓存在DRAM中的某个地方。如果是，系统还必须确定这个虚拟页存放在那个物理页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的那个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到DRAM中，替换这个牺牲页。

这些功能是由软硬件联合提供的，包括操作系统软件、MMU（内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做*页表（page table）*的数据结构，页表将虚拟页映射到物理页。每一次地址翻译硬件将一个虚拟地址转换成为物理地址的时候都会读取页表。操作系统负责维护页表的内容，以及在磁盘与DRAM之间来回传递页。

#### 3.3. 页命中

当CPU想要读取缓存在DRAM中的虚拟内存中的一个字时，就会发生页命中。

#### 3.4. 缺页

在虚拟内存的习惯说法中，DRAM缓存不命中称为*缺页（page fault）*。下面通过一个例子展现在缺页时我们的计算机会发生的变化。

1. CPU引用VP3页中的一个字，VP3并未缓存在DRAM中。触发缺页异常。
2. 地址翻译硬件从内存中读取PET3，从有效位推断出VP3未被缓存，并且触发一个缺页异常。
3. 缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页，例如存放在PP3中的VP4。如果VP4已经被修改，那么内核将它复制回磁盘。
4. 内核修改VP4的页表条目，反应VP4不再缓存在主存中。
5. 内核从磁盘复制VP3到内存中的PP3，更新PTE3，随后返回。
6. 重新启动触发缺页异常之前的指令。

虚拟内存是在SRAM引入之前被提出。因此虚拟内存系统使用了和SRAM缓存不同的术语。例如在虚拟内存中，块被称为页。在磁盘和内存之间传送页的活动被叫做*交换（swapping）*或者*页面调度（paging）*。页从磁盘*换入*（或者页面调入）DRAM和从DRAM*换出*（或者页面调出）磁盘。只有当不命中发生时，才换入页面这种策略被称为*按需页面调度（demand paging）*。也可以采用其他方式，例如尝试预测不命中，在页面实际被引入之前就换入页面。现代系统大部分都是使用按需调度的方式

#### 3.5. 局部性

通常整个运行过程中程序引用的不同页面的总数可能超过物理内存的总的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的*活动页面（active page）*集合上面工作，这个集合叫做*工作集（working set）*或者*常驻集合（resident set）*。在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。

只要程序具有良好的时间局部性，虚拟内存系统就能工作得相当的好。如果工作集的大小超出了物理内存的大小，那么程序将产生一种*抖动（thrashing）*，这时页面将不断地换进换出。

> 可以利用Linux的getrusage函数检测缺页的数量。

### 4. 虚拟内存作为内存管理工具

实际上，操作系统为每一个进程提供了一个独立的页表。注意多个虚拟页面可以映射到同一个共享物理页面。

按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。特别地，VM简化了链接和加载、代码和数据共享，以及应用程序的内存分配。

* **简化链接 ：** 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。这样的一致性极大地简化了链接器的设计和实现，允许连接器生成完全链接的可执行文件，这些可执行文件是独立于物理内存中的代码和数据的最终位置的。
* **简化加载 ：** 虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目标文件中的.text 和.data 节加载到一个新创建的进程中，Linux加载器为代码和数据段分配虚拟页，并将它们标记成为无效的（即未被缓存的），将页表条目指向目标文件中适当的位置，有趣的是，加载器从不从磁盘到内存实际复制任何数据。在每个页初次被引用时，要么时CPU取指令时引用的，要么时一条正在执行的指令引用一个内存位置时引用的，虚拟内存系统会按照需要自动地调入数据页。
* **简化共享 ：** 独立的地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。一般来说，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。在这种情况中，操作系统创建页表，将相应的虚拟页映射到不连续的物理页面中。
* **简化内存分配 ：** 虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间的时候（如调用malloc），操作系统分配一个适当的数字个连续的虚拟内存页面，并将它们映射到物理内存中任意位置的物理页面。由于页表的存在，这里操作系统并不需要分配k个连续的物理内存页面，页面可以随机的分散在物理内存中。

> 将一组连续的虚拟页映射到任意一个文件中的任意位置的表示方式称作*内存映射（memory mapping）*。Linux提供了一个称为mmap的系统调用，允许应用程序自己做内存映射。

> 在一些情况中，还是需要进程来共享代码和数据。例如，每个进程必须调用相同的操作系统内核代码，而每个C程序都会调用C标准库中的代码，如printf。操作系统通过将不同进程中适当的虚拟页映射到相同的物理页面中，从而安排多个进程共享这部分代码的一个副本，而不是在每个进程中都包括单独的内核和C标准库的副本。

### 5. 虚拟内存作为内存保护的工具

现代计算机系统必须要为操作系统提供手段来控制对内存系统的访问，不应该允许一个用户进程修改它的只读代码段。而且也不应该允许它读或者修改任何内核中的代码和数据结构。不应该允许它读或者写其他进程的私有内存，并且不允许它修改任何与其他进程共享的虚拟页面。除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）。

提供独立的地址空间使得区分不同进程的私有内存变得容易。但是地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因此每次CPU生成一个地址时，地址翻译硬件都会读一个PTE，所以一般通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问。如读权限/写权限/用户组的许可位。

如果一条指令违反了这些许可条件，那么CPU就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序，Linux shell一般将这种异常报告为"段错误（segmentation fault）"。

### 6. 地址翻译 

这里描述地址翻译的基础知识，帮助了解硬件在支持虚拟内存中的角色。下面先总结一下地址翻译常用的符号。

**基本参数**

| 符号 | 描述 |
|:-|:-|
| N=2^n | 虚拟地址空间中地址的数量 |
| M=2^m | 物理地址空间中地址的数量 |
| P=2^p | 页的大小（字节）|

**虚拟地址（VA）的组成部分**

| 符号 | 描述 |
|:-|:-|
| VPO | 虚拟页面地址偏移量（字节） |
| VPN | 虚拟页号 |
| TLBI | TLB索引 |
| TLBT | TLB标记 |

**物理地址（PA）的组成部分**

| 符号 | 描述 |
|:-|:-|
| PPO | 物理页面偏移量（字节） |
| PPN | 物理页号 |
| CO | 缓冲块内的字节偏移量 |
| CI | 高速缓存索引 |
| CT | 高速缓存标记 |

从形式上面来说，地址翻译是一个N元素的虚拟地址空间（VAS）中的元素和一个M元素的物理地址空间（PAS）中元素之间的映射。

下面描述MMU如何利用页表来实现这种映射。CPU中的一个控制寄存器，*页表基址寄存器（Page Table Base Register， PTBR）*指向当前页表。n位的虚拟地址包含两个部分：一个P位的*虚拟页面偏移（Virtual Page Offset，VPO）*和一个（n-p）位的*虚拟页号（Virtual Page Number， VPN）*，MMU利用VPN来选择适当的PTE。将页条目中的*物理页号（Physical Page Number，PPN）*和虚拟地址中的VPO串联起来，就得到相应的物理地址。

> 因为物理和虚拟页面都是P字节的，所以物理页面偏移PPO和VPO是相同的。

这里CPU硬件执行的步骤如下：

1. 处理器生成一个虚拟地址，并把它传送给MMU；
2. MMU生成PTE地址，并从高速缓存/主存请求得到它；
3. 高速缓存/主存向MMU返回PTE；
4. MMU构造物理地址，并把它传送给高速缓存/主存；
5. 高速缓存/主存返回所请求的数据字给处理器。

当页面命中时完全是由硬件来处理，与之不同的是，处理缺页要求硬件和操作系统内核协作完成，具体步骤如下：

1～3 同上
4. PTE中的有效位是0，所以MMU触发了一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序。
5. 缺页处理程序确定物理内存中的牺牲页，如果这个页已经被修改了，则把它换出到磁盘。
6. 缺页处理程序页面调入新的页面，并更新内存中的PTE。
7. 缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU将引起缺页的虚拟地址重新发送给MMU。因为虚拟页面现在缓存在物理内存中韩，所以就会命中。

#### 6.1. 结合高速缓存和虚拟内存


#### 6.2. 利用TLB加速地址翻译


#### 6.3. 多级页表


#### 6.4. 综合：端到端的地址翻译


### 7. 案例 


### 8. 内存映射 


### 9. 动态内存分配


### 10. 垃圾收集


### 11. 常见C语言中关于内存的错误

